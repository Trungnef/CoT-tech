# Báo cáo Đánh giá LLM

Thời gian tạo: 20250422_001527

## Tổng quan

- **Tổng số câu hỏi**: 2700
- **Câu trả lời đúng**: 2690
- **Accuracy tổng thể**: 99.63%

## Mô hình đã đánh giá

- **llama**: 892/900 câu đúng (accuracy: 99.11%) (F1 Score: 0.2165, METEOR: 0.3274, BERT Score: 0.6938)
- **qwen**: 899/900 câu đúng (accuracy: 99.89%) (F1 Score: 0.2013, METEOR: 0.3386, BERT Score: 0.6852)
- **gemini**: 899/900 câu đúng (accuracy: 99.89%) (F1 Score: 0.2477, METEOR: 0.3532, BERT Score: 0.7181)

## Loại Prompt đã đánh giá

- **zero_shot**: 299/300 câu đúng (accuracy: 99.67%)
- **few_shot_3**: 299/300 câu đúng (accuracy: 99.67%)
- **few_shot_5**: 300/300 câu đúng (accuracy: 100.00%)
- **few_shot_7**: 297/300 câu đúng (accuracy: 99.00%)
- **cot**: 299/300 câu đúng (accuracy: 99.67%)
- **cot_self_consistency_3**: 300/300 câu đúng (accuracy: 100.00%)
- **cot_self_consistency_5**: 300/300 câu đúng (accuracy: 100.00%)
- **cot_self_consistency_7**: 300/300 câu đúng (accuracy: 100.00%)
- **react**: 296/300 câu đúng (accuracy: 98.67%)

## Đánh giá độ tương đồng văn bản

Các metrics đánh giá độ tương đồng giữa câu trả lời của mô hình và đáp án chuẩn:

| Metric | Mô tả | Giá trị trung bình |
| --- | --- | --- |
| F1_SCORE | Đánh giá độ tương đồng văn bản | 0.2218 |
| METEOR_SCORE | Đánh giá chất lượng dịch thuật | 0.3397 |
| BERT_SCORE | Đánh giá độ tương đồng ngữ nghĩa | 0.6990 |


## Biểu đồ

### Accuracy By Model

Accuracy trung bình theo từng model

![Accuracy By Model](..\plots\accuracy_by_model_20250422_001527.png)

### Accuracy By Prompt

Accuracy trung bình theo từng loại prompt

![Accuracy By Prompt](..\plots\accuracy_by_prompt_20250422_001527.png)

### Accuracy Heatmap

Accuracy chi tiết theo model và prompt

![Accuracy Heatmap](..\plots\accuracy_heatmap_20250422_001527.png)

### Simple Comparison

So sánh hiệu suất tổng thể giữa các model

![Simple Comparison](..\plots\model_comparison_20250422_001527.png)

### Reasoning Criteria

Đánh giá các tiêu chí suy luận theo model

![Reasoning Criteria](..\plots\reasoning_criteria_plot_20250422_001527.png)

### Reasoning By Prompt

Chất lượng suy luận trung bình theo loại prompt

![Reasoning By Prompt](..\plots\reasoning_by_prompt_plot_20250422_001527.png)

### Reasoning By Question Type

Chất lượng suy luận phân theo loại câu hỏi

![Reasoning By Question Type](..\plots\reasoning_by_question_type_20250422_001527.png)

### Criteria Evaluation

Đánh giá theo các tiêu chí chất lượng

![Criteria Evaluation](..\plots\criteria_evaluation_20250422_001527.png)

### Criteria Radar

Đánh giá đa tiêu chí theo dạng radar chart

![Criteria Radar](..\plots\criteria_radar_20250422_001527.png)

### Difficulty Performance

Hiệu suất trên các câu hỏi có độ khó khác nhau

![Difficulty Performance](..\plots\difficulty_performance_20250422_001527.png)

### Context Adherence

Độ phù hợp ngữ cảnh theo model và prompt

![Context Adherence](..\plots\context_adherence_20250422_001527.png)

### Exact Match

Exact Match Score đánh giá sự khớp chính xác giữa câu trả lời và đáp án

![Exact Match](..\plots\exact_match_score_20250422_001527.png)

### Rouge Scores

ROUGE Score đánh giá độ tương đồng văn bản và chất lượng tóm tắt

![Rouge Scores](..\plots\rouge_scores_20250422_001527.png)

### Bleu Scores

BLEU Score đánh giá chất lượng dịch thuật và sinh văn bản

![Bleu Scores](..\plots\bleu_scores_20250422_001527.png)

### F1 Score

F1_SCORE đánh giá độ tương đồng văn bản dựa trên sự trùng lặp từ ngữ giữa câu trả lời và đáp án chuẩn. Giá trị từ 0-1, càng cao càng tốt.

![F1 Score](..\plots\f1_score_20250422_001527.png)

### Meteor Score

METEOR_SCORE là thước đo đánh giá chất lượng dịch thuật, tính cả khả năng khớp từ vựng, đồng nghĩa và cấu trúc. Giá trị từ 0-1, càng cao càng tốt.

![Meteor Score](..\plots\meteor_score_20250422_001527.png)

### Bert Score

BERT_SCORE đánh giá độ tương đồng ngữ nghĩa sử dụng mô hình ngôn ngữ BERT, xét đến ngữ cảnh sâu hơn so với chỉ đếm từ. Giá trị từ 0-1, càng cao càng tốt.

![Bert Score](..\plots\bert_score_20250422_001527.png)


## Kết quả chi tiết

| Model | Prompt | Accuracy | F1_SCORE | METEOR_SCORE | BERT_SCORE |
| --- | --- | --- | --- | --- | --- |
| llama | zero_shot | 99.00% | 0.2752 | 0.3541 | 0.7161 |
| llama | few_shot_3 | 99.00% | 0.2638 | 0.3560 | 0.7113 |
| llama | few_shot_5 | 100.00% | 0.3095 | 0.3966 | 0.7305 |
| llama | few_shot_7 | 98.00% | 0.3273 | 0.4064 | 0.7372 |
| llama | cot | 99.00% | 0.1978 | 0.3237 | 0.6907 |
| llama | cot_self_consistency_3 | 100.00% | 0.1433 | 0.2763 | 0.6686 |
| llama | cot_self_consistency_5 | 100.00% | 0.1414 | 0.2710 | 0.6704 |
| llama | cot_self_consistency_7 | 100.00% | 0.1409 | 0.2713 | 0.6653 |
| llama | react | 97.00% | 0.1492 | 0.2911 | 0.6536 |
| qwen | zero_shot | 100.00% | 0.2109 | 0.3569 | 0.6900 |
| qwen | few_shot_3 | 100.00% | 0.2132 | 0.3464 | 0.6990 |
| qwen | few_shot_5 | 100.00% | 0.2246 | 0.3708 | 0.7039 |
| qwen | few_shot_7 | 100.00% | 0.2278 | 0.3765 | 0.7092 |
| qwen | cot | 100.00% | 0.2115 | 0.3606 | 0.6945 |
| qwen | cot_self_consistency_3 | 100.00% | 0.1667 | 0.2927 | 0.6595 |
| qwen | cot_self_consistency_5 | 100.00% | 0.1716 | 0.2909 | 0.6605 |
| qwen | cot_self_consistency_7 | 100.00% | 0.1774 | 0.3085 | 0.6597 |
| qwen | react | 99.00% | 0.2080 | 0.3443 | 0.6905 |
| gemini | zero_shot | 100.00% | 0.3217 | 0.4239 | 0.7419 |
| gemini | few_shot_3 | 100.00% | 0.4154 | 0.4720 | 0.7767 |
| gemini | few_shot_5 | 100.00% | 0.4022 | 0.4727 | 0.7770 |
| gemini | few_shot_7 | 99.00% | 0.4151 | 0.4894 | 0.7803 |
| gemini | cot | 100.00% | 0.2132 | 0.3598 | 0.6994 |
| gemini | cot_self_consistency_3 | 100.00% | 0.1008 | 0.2250 | 0.6659 |
| gemini | cot_self_consistency_5 | 100.00% | 0.0883 | 0.2041 | 0.6651 |
| gemini | cot_self_consistency_7 | 100.00% | 0.0853 | 0.1990 | 0.6638 |
| gemini | react | 100.00% | 0.1873 | 0.3325 | 0.6927 |
