# Báo cáo Đánh giá LLM

Thời gian tạo: 20250419_035231

## Tổng quan

- **Tổng số câu hỏi**: 1167
- **Câu trả lời đúng**: 1160
- **Accuracy tổng thể**: 99.40%

## Mô hình đã đánh giá

- **llama**: 444/450 câu đúng (accuracy: 98.67%) (F1 Score: 0.2001, METEOR: 0.3155, BERT Score: 0.6851)
- **qwen**: 267/267 câu đúng (accuracy: 100.00%) (F1 Score: 0.2099, METEOR: 0.3613, BERT Score: 0.6942)
- **gemini**: 449/450 câu đúng (accuracy: 99.78%) (F1 Score: 0.2501, METEOR: 0.3541, BERT Score: 0.7178)

## Loại Prompt đã đánh giá

- **zero_shot**: 149/150 câu đúng (accuracy: 99.33%)
- **few_shot_3**: 150/150 câu đúng (accuracy: 100.00%)
- **few_shot_5**: 149/150 câu đúng (accuracy: 99.33%)
- **few_shot_7**: 149/150 câu đúng (accuracy: 99.33%)
- **cot**: 150/150 câu đúng (accuracy: 100.00%)
- **cot_self_consistency_3**: 117/117 câu đúng (accuracy: 100.00%)
- **cot_self_consistency_5**: 99/100 câu đúng (accuracy: 99.00%)
- **cot_self_consistency_7**: 99/100 câu đúng (accuracy: 99.00%)
- **react**: 98/100 câu đúng (accuracy: 98.00%)

## Đánh giá độ tương đồng văn bản

Các metrics đánh giá độ tương đồng giữa câu trả lời của mô hình và đáp án chuẩn:

| Metric | Mô tả | Giá trị trung bình |
| --- | --- | --- |
| F1_SCORE | Đánh giá độ tương đồng văn bản | 0.2216 |
| METEOR_SCORE | Đánh giá chất lượng dịch thuật | 0.3409 |
| BERT_SCORE | Đánh giá độ tương đồng ngữ nghĩa | 0.6998 |


## Biểu đồ

### Accuracy By Model

Accuracy trung bình theo từng model

![Accuracy By Model](..\plots\accuracy_by_model_20250419_035231.png)

### Accuracy By Prompt

Accuracy trung bình theo từng loại prompt

![Accuracy By Prompt](..\plots\accuracy_by_prompt_20250419_035231.png)

### Accuracy Heatmap

Accuracy chi tiết theo model và prompt

![Accuracy Heatmap](..\plots\accuracy_heatmap_20250419_035231.png)

### Simple Comparison

So sánh hiệu suất tổng thể giữa các model

![Simple Comparison](..\plots\model_comparison_20250419_035231.png)

### Reasoning Criteria

Đánh giá các tiêu chí suy luận theo model

![Reasoning Criteria](..\plots\reasoning_criteria_plot_20250419_035231.png)

### Reasoning By Prompt

Chất lượng suy luận trung bình theo loại prompt

![Reasoning By Prompt](..\plots\reasoning_by_prompt_plot_20250419_035231.png)

### Reasoning By Question Type

Chất lượng suy luận phân theo loại câu hỏi

![Reasoning By Question Type](..\plots\reasoning_by_question_type_20250419_035231.png)

### Criteria Evaluation

Đánh giá theo các tiêu chí chất lượng

![Criteria Evaluation](..\plots\criteria_evaluation_20250419_035231.png)

### Criteria Radar

Đánh giá đa tiêu chí theo dạng radar chart

![Criteria Radar](..\plots\criteria_radar_20250419_035231.png)

### Difficulty Performance

Hiệu suất trên các câu hỏi có độ khó khác nhau

![Difficulty Performance](..\plots\difficulty_performance_20250419_035231.png)

### Context Adherence

Độ phù hợp ngữ cảnh theo model và prompt

![Context Adherence](..\plots\context_adherence_20250419_035231.png)

### F1 Score

F1_SCORE đánh giá độ tương đồng văn bản dựa trên sự trùng lặp từ ngữ giữa câu trả lời và đáp án chuẩn. Giá trị từ 0-1, càng cao càng tốt.

![F1 Score](..\plots\f1_score_20250419_035231.png)

### Meteor Score

METEOR_SCORE là thước đo đánh giá chất lượng dịch thuật, tính cả khả năng khớp từ vựng, đồng nghĩa và cấu trúc. Giá trị từ 0-1, càng cao càng tốt.

![Meteor Score](..\plots\meteor_score_20250419_035231.png)

### Bert Score

BERT_SCORE đánh giá độ tương đồng ngữ nghĩa sử dụng mô hình ngôn ngữ BERT, xét đến ngữ cảnh sâu hơn so với chỉ đếm từ. Giá trị từ 0-1, càng cao càng tốt.

![Bert Score](..\plots\bert_score_20250419_035231.png)


## Kết quả chi tiết

| Model | Prompt | Accuracy | F1_SCORE | METEOR_SCORE | BERT_SCORE |
| --- | --- | --- | --- | --- | --- |
| llama | zero_shot | 98.00% | 0.2551 | 0.3419 | 0.7020 |
| llama | few_shot_3 | 100.00% | 0.2391 | 0.3314 | 0.6960 |
| llama | few_shot_5 | 100.00% | 0.2286 | 0.3359 | 0.6998 |
| llama | few_shot_7 | 98.00% | 0.3224 | 0.4101 | 0.7375 |
| llama | cot | 100.00% | 0.2037 | 0.3364 | 0.6890 |
| llama | cot_self_consistency_3 | 100.00% | 0.1356 | 0.2703 | 0.6688 |
| llama | cot_self_consistency_5 | 98.00% | 0.1342 | 0.2698 | 0.6667 |
| llama | cot_self_consistency_7 | 98.00% | 0.1276 | 0.2557 | 0.6576 |
| llama | react | 96.00% | 0.1544 | 0.2881 | 0.6481 |
| qwen | zero_shot | 100.00% | 0.2140 | 0.3662 | 0.6898 |
| qwen | few_shot_3 | 100.00% | 0.2176 | 0.3616 | 0.6948 |
| qwen | few_shot_5 | 100.00% | 0.2131 | 0.3715 | 0.7008 |
| qwen | few_shot_7 | 100.00% | 0.2235 | 0.3840 | 0.7092 |
| qwen | cot | 100.00% | 0.1947 | 0.3416 | 0.6866 |
| qwen | cot_self_consistency_3 | 100.00% | 0.1708 | 0.3074 | 0.6645 |
| gemini | zero_shot | 100.00% | 0.3242 | 0.4284 | 0.7421 |
| gemini | few_shot_3 | 100.00% | 0.4029 | 0.4545 | 0.7669 |
| gemini | few_shot_5 | 98.00% | 0.4330 | 0.4906 | 0.7861 |
| gemini | few_shot_7 | 100.00% | 0.4391 | 0.5077 | 0.7905 |
| gemini | cot | 100.00% | 0.2099 | 0.3511 | 0.6982 |
| gemini | cot_self_consistency_3 | 100.00% | 0.0964 | 0.2236 | 0.6633 |
| gemini | cot_self_consistency_5 | 100.00% | 0.0839 | 0.1995 | 0.6627 |
| gemini | cot_self_consistency_7 | 100.00% | 0.0827 | 0.2027 | 0.6621 |
| gemini | react | 100.00% | 0.1786 | 0.3285 | 0.6888 |
