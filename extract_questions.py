import os
import fitz  # PyMuPDF
import re
import json
from tqdm import tqdm
from typing import List, Dict

class QuestionExtractor:
    def __init__(self, pdf_path: str):
        self.pdf_path = pdf_path
        self.questions_dir = 'db/questions'
        os.makedirs(self.questions_dir, exist_ok=True)
        
    def extract_questions(self):
        doc = fitz.open(self.pdf_path)
        current_section = None
        questions = []
        current_question = None
        question_text = []
        solution_text = []
        is_in_solution = False
        
        for page in doc:
            text = page.get_text()
            # X·ª≠ l√Ω c√°c k√Ω t·ª± xu·ªëng d√≤ng ƒë·∫∑c bi·ªát v√† d·∫•u c√¢u
            text = text.replace('\r\n', ' ').replace('\n\n', '\n').strip()
            text = re.sub(r'\s+', ' ', text)  # Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
            lines = [line.strip() for line in text.split('\n') if line.strip()]
            
            for line in lines:
                # T√¨m ph·∫ßn m·ªõi
                if line.startswith('Ph·∫ßn'):
                    if current_section and questions:
                        self._save_questions(current_section, questions)
                        questions = []
                    current_section = line.split(': ')[1].strip()
                    continue
                
                # T√¨m c√¢u h·ªèi m·ªõi
                if line.startswith('B√†i'):
                    if current_question:
                        if question_text:
                            current_question['question'] = ' '.join(question_text)
                        if solution_text:
                            current_question['solution'] = ' '.join(solution_text)
                        questions.append(current_question)
                    
                    # Reset cho c√¢u h·ªèi m·ªõi
                    current_question = {
                        'id': len(questions) + 1,
                        'question': '',
                        'solution': '',
                        'type': current_section
                    }
                    question_text = []
                    solution_text = []
                    is_in_solution = False
                    continue
                
                # X√°c ƒë·ªãnh ph·∫ßn h∆∞·ªõng d·∫´n gi·∫£i
                if 'H∆∞·ªõng d·∫´n gi·∫£i' in line or 'L·ªùi gi·∫£i' in line or 'Gi·∫£i' in line:
                    is_in_solution = True
                    continue
                
                # Th√™m n·ªôi dung v√†o c√¢u h·ªèi ho·∫∑c l·ªùi gi·∫£i
                if current_question:
                    if not is_in_solution:
                        question_text.append(line)
                    else:
                        solution_text.append(line)
        
        # X·ª≠ l√Ω c√¢u h·ªèi cu·ªëi c√πng
        if current_question:
            if question_text:
                current_question['question'] = ' '.join(question_text)
            if solution_text:
                current_question['solution'] = ' '.join(solution_text)
            questions.append(current_question)
        
        # L∆∞u ph·∫ßn cu·ªëi c√πng
        if current_section and questions:
            self._save_questions(current_section, questions)
        
        doc.close()
        print(f"‚úÖ ƒê√£ tr√≠ch xu·∫•t xong c√°c c√¢u h·ªèi t·ª´ file PDF")
    
    def _save_questions(self, section: str, questions: List[Dict]):
        # Chu·∫©n h√≥a t√™n file
        filename = section.lower().replace(' ', '_')
        filename = re.sub(r'[^a-z0-9_]', '', filename)
        filepath = os.path.join(self.questions_dir, f'{filename}.json')
        
        # Chu·∫©n h√≥a d·ªØ li·ªáu v√† x·ª≠ l√Ω vƒÉn b·∫£n
        for q in questions:
            # Chu·∫©n h√≥a c√¢u h·ªèi
            q['question'] = self._normalize_text(q['question'])
            # Chu·∫©n h√≥a l·ªùi gi·∫£i
            q['solution'] = self._normalize_text(q['solution'])
            # Th√™m metadata
            q['difficulty'] = self._estimate_difficulty(q['question'], q['solution'])
            q['tags'] = self._extract_tags(q['question'])
        
        # L∆∞u file JSON v·ªõi ƒë·ªãnh d·∫°ng ƒë·∫πp
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump({
                'section': section,
                'questions': questions
            }, f, ensure_ascii=False, indent=2)
        
        print(f"‚úì ƒê√£ l∆∞u {len(questions)} c√¢u h·ªèi t·ª´ ph·∫ßn '{section}' v√†o {filepath}")
    
    def _normalize_text(self, text: str) -> str:
        if not text:
            return ""
        # Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
        text = re.sub(r'\s+', ' ', text)
        # Chu·∫©n h√≥a d·∫•u c√¢u
        text = re.sub(r'\s*([.,!?])\s*', r'\1 ', text)
        # Chu·∫©n h√≥a d·∫•u ngo·∫∑c
        text = re.sub(r'\s*([()[\]])\s*', r'\1', text)
        return text.strip()
    
    def _estimate_difficulty(self, question: str, solution: str) -> str:
        # ∆Ø·ªõc l∆∞·ª£ng ƒë·ªô kh√≥ d·ª±a tr√™n ƒë·ªô d√†i v√† ƒë·ªô ph·ª©c t·∫°p
        complexity = len(solution.split()) / len(question.split()) if question else 1
        if complexity > 2:
            return "Kh√≥"
        elif complexity > 1.5:
            return "Trung b√¨nh"
        return "D·ªÖ"
    
    def _extract_tags(self, question: str) -> List[str]:
        # Tr√≠ch xu·∫•t t·ª´ kh√≥a quan tr·ªçng
        keywords = {
            's·ªë h·ªçc': ['s·ªë', 'ch·ªØ s·ªë', '∆∞·ªõc s·ªë', 'b·ªôi s·ªë', 't·ªïng', 'hi·ªáu', 't√≠ch', 'th∆∞∆°ng'],
            'h√¨nh h·ªçc': ['tam gi√°c', 'h√¨nh vu√¥ng', 'h√¨nh ch·ªØ nh·∫≠t', 'di·ªán t√≠ch', 'chu vi'],
            'ƒë·∫°i s·ªë': ['ph∆∞∆°ng tr√¨nh', 'bi·ªÉu th·ª©c', 's·ªë x', 'nghi·ªám'],
            'logic': ['n·∫øu', 'th√¨', 'ho·∫∑c', 'v√†', 'suy ra'],
            'th·ª±c t·∫ø': ['ti·ªÅn', 'tu·ªïi', 'gi·ªù', 'ng√†y', 'th√°ng', 'nƒÉm']
        }
        
        tags = []
        text = question.lower()
        for category, words in keywords.items():
            if any(word in text for word in words):
                tags.append(category)
        return tags

    def get_statistics(self):
        total_questions = 0
        sections = {}
        
        for filename in os.listdir(self.questions_dir):
            if filename.endswith('.json'):
                filepath = os.path.join(self.questions_dir, filename)
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    count = len(data.get('questions', []))
                    sections[os.path.splitext(filename)[0]] = count
                    total_questions += count
        
        print("\nüìä Th·ªëng k√™:")
        print(f"T·ªïng s·ªë c√¢u h·ªèi: {total_questions}")
        print("\nPh√¢n b·ªë theo ph·∫ßn:")
        for section, count in sections.items():
            print(f"- {section}: {count} c√¢u")

if __name__ == '__main__':
    extractor = QuestionExtractor('db/Nhung_bai_toan_co_dien.pdf')
    extractor.extract_questions()
    extractor.get_statistics() 